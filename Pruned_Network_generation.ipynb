{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruned Network generation for NH-AMPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from itertools import product\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neural_horizon import NN_for_casadi, load_NN\n",
    "from src.parameters import NH_AMPC_Param\n",
    "from src.utils import get_features_and_labels\n",
    "from src.torch_utils import count_parameters\n",
    "\n",
    "from src.pruning.prun_dataclasses import Node_Prun_LTH, Node_Prun_Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.abspath('Results')\n",
    "MPC_DATASETS_DIR = os.path.join(RESULTS_DIR, 'MPC_data_gen')\n",
    "NNS_DIR = os.path.join(RESULTS_DIR, 'Trained_Networks')\n",
    "PRUNED_NNS_DIR = os.path.join(RESULTS_DIR, 'Prun_Networks')\n",
    "\n",
    "NUM_SAMPLES = 30_000\n",
    "\n",
    "RETRAIN_NNS = False         # Skip training of networks if already existent\n",
    "PRUNE_NNS = True            # Can be set to False to get only the scores of existing ones\n",
    "NUM_NNS = 50\n",
    "\n",
    "USE_CUDA = True\n",
    "\n",
    "DROP_OLD_R2SCORES = False\n",
    "\n",
    "MPC_PARAM_DICT = {\n",
    "    'T_sim': 5, # length of the closed-loop simulation (in seconds)\n",
    "}\n",
    "\n",
    "NH_AMPC_OPTIONS = [tup for tup in product(\n",
    "    (8, ),                                      # N_MPC\n",
    "    (17, ),                                     # N_NN -> if USE_BEGINING_OF_DATASET != 'begin, it has to be 70-max(N_MPCs)\n",
    "    (70, ),                                     # N_DATASET\n",
    "    (5, ),                                      # TRAIN_DATASET_VERSION\n",
    "    (6, ),                                      # TEST_DATASET_VERSION\n",
    "    ('fixed', ),                                # USE_BEGINING_OF_DATASET ('begin', 'fixed', '') if '' use DS_FEATURE of N_MPC\n",
    "    (8, ),                                      # DS_FEATURE_IF_FIXED\n",
    "    ('RTI_PCHPIPM_DISCRETE', ),                 # DATASET_NAME_ADD ('RTI_PCHPIPM_DISCRETE', 'RTI_PCHPIPM_DISCRETE_50ITER', 'RTI_PCHPIPM_ROBUST_DISCRETE')\n",
    "    (48, ),                                     # HIDDEN_NEURONS\n",
    "    (24, ),                           # END_HIDDEN_SIZES (left from pruning)\n",
    ")]\n",
    "\n",
    "NH_AMPC_OPTIONS.extend([tup for tup in product(\n",
    "    (8, ),                                      # N_MPC\n",
    "    (22, ),                                     # N_NN -> if USE_BEGINING_OF_DATASET != 'begin, it has to be 70-max(N_MPCs)\n",
    "    (70, ),                                     # N_DATASET\n",
    "    (5, ),                                      # TRAIN_DATASET_VERSION\n",
    "    (6, ),                                      # TEST_DATASET_VERSION\n",
    "    ('fixed', ),                                # USE_BEGINING_OF_DATASET ('begin', 'fixed', '') if '' use DS_FEATURE of N_MPC\n",
    "    (8, ),                                      # DS_FEATURE_IF_FIXED\n",
    "    ('RTI_PCHPIPM_DISCRETE', ),                 # DATASET_NAME_ADD ('RTI_PCHPIPM_DISCRETE', 'RTI_PCHPIPM_DISCRETE_50ITER', 'RTI_PCHPIPM_ROBUST_DISCRETE')\n",
    "    (64, ),                                     # HIDDEN_NEURONS\n",
    "    (24, 32, ),                           # END_HIDDEN_SIZES (left from pruning)\n",
    ")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(NH_AMPC_OPTIONS)\n",
    "print(NNS_DIR)\n",
    "print(PRUNED_NNS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters needed for neural horizon acados MPC\n",
    "NH_AMPC_PARAMS = [\n",
    "    NH_AMPC_Param(\n",
    "        # Param\n",
    "        N_MPC = N_MPC, \n",
    "        N = N_NN+N_MPC,\n",
    "\n",
    "        # Dataset stuff\n",
    "        N_DS = N_DSET, \n",
    "        TRAIN_V_DS = TRAIN_DATASET_VERSION, \n",
    "        TEST_V_DS = TEST_DATASET_VERSION, \n",
    "        DS_begin = USE_BEGIN,\n",
    "        DS_samples = NUM_SAMPLES,\n",
    "        DS_opts_name = DS_OPT_NAME,\n",
    "        DS_feature = DS_FEATURES,\n",
    "\n",
    "        # NN stuff\n",
    "        V_NN = NN_VERSION,\n",
    "        N_hidden = N_HIDDEN,\n",
    "        N_hidden_end = END_N_SIZES,\n",
    "\n",
    "        # Param\n",
    "        **MPC_PARAM_DICT\n",
    "    ) for NN_VERSION in range(NUM_NNS) \\\n",
    "        for N_MPC, N_NN, N_DSET, TRAIN_DATASET_VERSION, TEST_DATASET_VERSION, USE_BEGIN,\\\n",
    "            DS_FEATURES, DS_OPT_NAME, N_HIDDEN, END_N_SIZES in NH_AMPC_OPTIONS \\\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() and USE_CUDA else 'cpu') \n",
    "dtype = torch.float32\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(NNS_DIR):\n",
    "    nn_paths = os.listdir(NNS_DIR)\n",
    "else:\n",
    "    nn_paths = []\n",
    "\n",
    "\n",
    "with tqdm_notebook(total=len(NH_AMPC_PARAMS), unit='Networks', desc='Network train progress: ') as tqdm_handle:\n",
    "    for nh_ampc_params in NH_AMPC_PARAMS:\n",
    "        name = f'{nh_ampc_params.N_MPC}M_{nh_ampc_params.N_NN}N {nh_ampc_params.N_hidden}Nh_{nh_ampc_params.V_NN}v' \\\n",
    "            if nh_ampc_params.N_hidden_end is None else \\\n",
    "            f'{nh_ampc_params.N_MPC}M_{nh_ampc_params.N_NN}N {nh_ampc_params.N_hidden}Nh_{nh_ampc_params.N_hidden_end}NhP_{nh_ampc_params.V_NN}v'\n",
    "        tqdm_handle.set_description_str(f'Get trajectory of:\\n{name}')\n",
    "        \n",
    "        # skip already existent NNs\n",
    "        if nh_ampc_params.NN_name in nn_paths and not RETRAIN_NNS:\n",
    "            tqdm_handle.update(1)\n",
    "            continue\n",
    "        \n",
    "        mpc_dataset_file = os.path.join(MPC_DATASETS_DIR, nh_ampc_params.train_DS_name)\n",
    "\n",
    "        features, labels = get_features_and_labels(nh_ampc_params)\n",
    "        Unpruned_NN_fc = NN_for_casadi(\n",
    "            mpc_dataset_file, \n",
    "            nh_ampc_params, \n",
    "            features=features,\n",
    "            labels=labels,\n",
    "            device=device, \n",
    "            dtype=dtype\n",
    "        )\n",
    "        Unpruned_NN_fc.NNcompile(show_tqdm=False, n_neurons=nh_ampc_params.N_hidden)\n",
    "        Unpruned_NN_fc.NNsave(file=nh_ampc_params.NN_name, filedir=NNS_DIR)\n",
    "\n",
    "        tqdm_handle.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune and retrain Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRUNE_NNS:\n",
    "    with tqdm_notebook(total=len(NH_AMPC_PARAMS), unit='Networks', desc='Network prun progress: ') as tqdm_handle:\n",
    "        for nh_ampc_params in NH_AMPC_PARAMS:\n",
    "            name = f'{nh_ampc_params.N_MPC}M_{nh_ampc_params.N_NN}N {nh_ampc_params.N_hidden}Nh_{nh_ampc_params.V_NN}v' \\\n",
    "                if nh_ampc_params.N_hidden_end is None else \\\n",
    "                f'{nh_ampc_params.N_MPC}M_{nh_ampc_params.N_NN}N {nh_ampc_params.N_hidden}Nh_{nh_ampc_params.N_hidden_end}NhP_{nh_ampc_params.V_NN}v'\n",
    "            tqdm_handle.set_description_str(f'Prune NN:\\n{name}')\n",
    "             \n",
    "            Pruned_NN_fc = load_NN(nh_ampc_params, NNS_DIR, MPC_DATASETS_DIR, device, dtype, force_load_unpruned=True)\n",
    "    \n",
    "            amount = Pruned_NN_fc.NN.n_neurons[1] - nh_ampc_params.N_hidden_end\n",
    "            prun_params = Node_Prun_LTH(1, amount, dim=1)\n",
    "            Pruned_NN_fc.NNprunCasadi(prun_params, show_tqdm=False)\n",
    "            Pruned_NN_fc.NNsave(file=nh_ampc_params.Pruned_NN_name, filedir=PRUNED_NNS_DIR)\n",
    "            \n",
    "            tqdm_handle.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_evals = []\n",
    "\n",
    "for nh_ampc_params in NH_AMPC_PARAMS:\n",
    "    print('#' + '='*100)    \n",
    "    Pruned_NN_fc = load_NN(nh_ampc_params, PRUNED_NNS_DIR, MPC_DATASETS_DIR, device, dtype)\n",
    "\n",
    "    test_datasets_file = os.path.join(MPC_DATASETS_DIR, nh_ampc_params.test_DS_name)\n",
    "    r2_score, relative_error = Pruned_NN_fc.evaluate_NN(test_datasets_file)\n",
    "    \n",
    "    NN_evals.append({\n",
    "        'N_NN': nh_ampc_params.N_NN,\n",
    "        'N_hidden': nh_ampc_params.N_hidden,\n",
    "        'N_hidden_end': nh_ampc_params.N_hidden_end,\n",
    "        'Version': nh_ampc_params.V_NN,\n",
    "        'R2_score': r2_score, \n",
    "        'Rel_err_mean': 100*relative_error.mean(),\n",
    "        'Rel_err_std': 100*relative_error.std(),\n",
    "        'NN_param_size': count_parameters(Pruned_NN_fc.NN),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame.from_dict(NN_evals).set_index(['N_NN', 'N_hidden', 'N_hidden_end', 'Version'])\n",
    "scores.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = os.path.join(RESULTS_DIR, 'PrunedR2scores.pkl')\n",
    "\n",
    "if not DROP_OLD_R2SCORES and os.path.exists(scores_path):\n",
    "    existing_scores = pd.read_pickle(scores_path)s\n",
    "    scores = existing_scores.append(scores)\n",
    "    scores = scores[~scores.index.duplicated(keep='last')]\n",
    "    \n",
    "scores.to_pickle(scores_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acados_kernel",
   "language": "python",
   "name": "acados_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
